{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e547f",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, getpass\n",
    "\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e4f2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from typing_extensions import Literal\n",
    "\n",
    "# LLM\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(groq_api_key=GROQ_API_KEY,model='gemma2-9b-it')\n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State)-> Literal [\"summarize_conversation\",END]:\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content=\"Hello Lance, it's nice to meet you! ðŸ‘‹\\n\\nWhat can I do for you today? ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 15, 'total_tokens': 40, 'completion_time': 0.045454545, 'prompt_time': 0.00125187, 'queue_time': 0.255098429, 'total_time': 0.046706415}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--34a3aa4e-fddf-4c09-a5d0-d9ed3da93bee-0', usage_metadata={'input_tokens': 15, 'output_tokens': 25, 'total_tokens': 40})}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! ðŸ‘‹ \n",
      "\n",
      "It's great to meet you. What can I help you with today? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Lance, it's nice to meet you! ðŸ‘‹\n",
      "\n",
      "What can I do for you today? ðŸ˜„\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGroq\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatGroq\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' professional', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' American', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' football', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' based', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Santa', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Clara', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' California', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='Here', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=\"'\", additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' rundown', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' key', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' information', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' about', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' them', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='History', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='Founded', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='6', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='League', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' League', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='NFL', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='Conference', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='NFC', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='Division', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' NFC', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' West', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='Home', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Stadium', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Levi', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=\"'\", additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Stadium', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='Success', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Legacy', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='Super', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Champions', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='5', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' times', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='XVI', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' XIX', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' XXIII', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' XXIV', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' XXIX', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' -', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' recent', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' being', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='5', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='NFC', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Championships', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='8', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' times', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='Hall', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Fam', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='  ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' boast', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' legendary', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' roster', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Hall', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Fam', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Joe', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Montana', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Jerry', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Rice', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Ronnie', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Lott', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Steve', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Young', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Charles', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Haley', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='Notable', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Features', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Faithful', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' one', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' passionate', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' dedicated', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' fan', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' bases', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' \"', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Faithful', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='.\"', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='West', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Coast', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Offense', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='  ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' closely', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' associated', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' development', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' popular', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='ization', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' West', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Coast', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Offense', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' passing', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='oriented', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' offensive', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' scheme', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' its', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' short', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' quick', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' passes', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' timing', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='Red', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Gold', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Colors', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='  ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=\"'\", additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' iconic', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' red', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' gold', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' colors', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' instantly', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' recognizable', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='Dynamic', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Franchise', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='  ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='Despite', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' some', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ups', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' downs', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' consistently', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' competitive', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' success', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='Recent', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Seasons', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' playoff', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' contender', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' recent', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' years', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' consistently', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' making', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' deep', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' runs', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' postseason', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' reached', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' NFC', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Championship', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' game', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='2', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='2', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='2', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='2', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' but', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' fell', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' short', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' reaching', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' strong', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' defense', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' dynamic', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' offense', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' led', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' quarterback', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Brock', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Purdy', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='To', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' learn', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' more', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='Official', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Website', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' https', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='://', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='www', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='com', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='/', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='*', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='NFL', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' Website', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' https', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='://', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='www', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='nfl', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='com', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='/', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='teams', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='/', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='san', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='fran', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='cisco', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='/', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\n\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='Let', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' me', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' know', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' if', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' any', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' more', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' questions', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' about', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='!', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand'}, id='run--ad88edc6-c3a0-45ec-8842-848f1f8316e7', usage_metadata={'input_tokens': 19, 'output_tokens': 458, 'total_tokens': 477})}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|##| The| San| Francisco| |4|9|ers|:| A| Stor|ied| NFL| Dynasty|\n",
      "\n",
      "|The| San| Francisco| |4|9|ers| are| an| iconic| National| Football| League| (|NFL|)| franchise| with| a| rich| history| and| passionate| fan| base|.| |\n",
      "\n",
      "|**|Here|'|s| a| breakdown| of| some| key| aspects|:**|\n",
      "\n",
      "|*| **|Founded|:**| |1|9|4|6|\n",
      "|*| **|Home| Stadium|:**| Levi|'|s| Stadium| (|Santa| Clara|,| California|)|\n",
      "|*| **|Division|:**| NFC| West|\n",
      "|*| **|Conference|:**| NFC|\n",
      "|*| **|Colors|:**| Red|,| Gold|,| White|\n",
      "|*| **|Mas|cot|:**| Sour|dough| Sam|\n",
      "\n",
      "|**|Notable| Achievements|:**|\n",
      "\n",
      "|*| **|Super| Bowl| Champions|:**| |5| (|XVI|,| XIX|,| XXIII|,| XXIV|,| XXIX|)|\n",
      "|*| **|NFC| Championships|:**| |8|\n",
      "|*| **|NFL| Championships|:**| |1| (|1|9|5|7|)|\n",
      "\n",
      "|**|Legendary| Players|:**|\n",
      "\n",
      "|The| |4|9|ers| boast| a| roster| of| legendary| players| who| have| left| an| indelible| mark| on| the| NFL|.| Some| of| the| most| iconic| names| include|:|\n",
      "\n",
      "|*| **|Joe| Montana|:**| Hall| of| Fame| quarterback|,| known| for| his| poise| and| clutch| performances|.|\n",
      "|*| **|Jerry| Rice|:**| Widely| considered| the| greatest| wide| receiver| of| all| time|,| holding| numerous| NFL| records|.|\n",
      "|*| **|Steve| Young|:**|  |Hall| of| Fame| quarterback| who| led| the| |4|9|ers| to| their| third| Super| Bowl| victory|.|\n",
      "|*| **|Ronnie| Lott|:**|  |Hard|-|hitting| safety| and| defensive| leader|.|\n",
      "|*| **|Roger| Craig|:**|  |All|-|purpose| back| who| revolution|ized| the| running| back| position|.|\n",
      "\n",
      "|**|Coaching| Legacy|:**|\n",
      "\n",
      "|The| |4|9|ers| have| been| led| by| some| of| the| most| successful| coaches| in| NFL| history|,| including|:|\n",
      "\n",
      "|*| **|Bill| Walsh|:**|  |Hall| of| Fame| coach| who| built| the| dynasty| of| the| |1|9|8|0|s| and| revolution|ized| offensive| football|.|\n",
      "|*| **|George| Seif|ert|:**|  |Continued| the| winning| tradition| after| Bill| Walsh|,| leading| the| team| to| two| more| Super| Bowl| titles|.|\n",
      "\n",
      "|**|Recent| History|:**|\n",
      "\n",
      "|After| a| period| of| rebuilding|,| the| |4|9|ers| have| re|-|established| themselves| as| a| consistent| contender| in| the| NFL|.|  |Led| by| head| coach| Kyle| Shan|ahan| and| quarterback| Trey| Lance| (|currently| injured|,| with| Jimmy| Gar|op|polo| filling| in|),| they| have| reached| the| NFC| Championship| game| in| recent| years|.|\n",
      "\n",
      "\n",
      "|**|Overall|,| the| San| Francisco| |4|9|ers| are| a| legendary| NFL| franchise| with| a| stor|ied| past|,| iconic| players|,| and| a| bright| future|.**|\n",
      "||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {},
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "**âš ï¸ DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- ðŸš€ API: http://127.0.0.1:2024\n",
    "- ðŸŽ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- ðŸ“š API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'google.colab' in str(get_ipython()):\n",
    "#     raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7057e34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'assistant_id': '6f6fce9a-b777-529d-9699-dd340ddec86c',\n",
       "  'graph_id': 'dynamic_breakpoints',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'dynamic_breakpoints',\n",
       "  'created_at': '2025-10-02T21:46:49.338496+00:00',\n",
       "  'updated_at': '2025-10-02T21:46:49.338496+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       "  'graph_id': 'agent',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'agent',\n",
       "  'created_at': '2025-10-02T21:46:49.329576+00:00',\n",
       "  'updated_at': '2025-10-02T21:46:49.329576+00:00',\n",
       "  'version': 1,\n",
       "  'description': None}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '0199a6e4-f503-74f2-a4b3-bd02b77a6598', 'attempt': 1})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'd83d55f6-d6ce-4e3f-9127-5ed3a49fec76', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'd83d55f6-d6ce-4e3f-9127-5ed3a49fec76', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'xgcyy5tn1', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'token_usage': {'completion_tokens': 86, 'prompt_tokens': 1276, 'total_tokens': 1362, 'completion_time': 0.156363636, 'prompt_time': 0.024300797, 'queue_time': 0.257757862, 'total_time': 0.180664433}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--b2fda800-adc3-4676-9cbe-067c0962709b-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'xgcyy5tn1', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 1276, 'output_tokens': 86, 'total_tokens': 1362}}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'd83d55f6-d6ce-4e3f-9127-5ed3a49fec76', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'xgcyy5tn1', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'token_usage': {'completion_tokens': 86, 'prompt_tokens': 1276, 'total_tokens': 1362, 'completion_time': 0.156363636, 'prompt_time': 0.024300797, 'queue_time': 0.257757862, 'total_time': 0.180664433}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--b2fda800-adc3-4676-9cbe-067c0962709b-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'xgcyy5tn1', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 1276, 'output_tokens': 86, 'total_tokens': 1362}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '046e22cf-4137-4437-b764-173a3aad18e0', 'tool_call_id': 'xgcyy5tn1', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'd83d55f6-d6ce-4e3f-9127-5ed3a49fec76', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'xgcyy5tn1', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'token_usage': {'completion_tokens': 86, 'prompt_tokens': 1276, 'total_tokens': 1362, 'completion_time': 0.156363636, 'prompt_time': 0.024300797, 'queue_time': 0.257757862, 'total_time': 0.180664433}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--b2fda800-adc3-4676-9cbe-067c0962709b-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'xgcyy5tn1', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 1276, 'output_tokens': 86, 'total_tokens': 1362}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '046e22cf-4137-4437-b764-173a3aad18e0', 'tool_call_id': 'xgcyy5tn1', 'artifact': None, 'status': 'success'}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {'token_usage': {'completion_tokens': 3, 'prompt_tokens': 1351, 'total_tokens': 1354, 'completion_time': 0.005454545, 'prompt_time': 0.025636317, 'queue_time': 0.256850182, 'total_time': 0.031090862}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--db9d65d9-da03-4447-bbec-7faab5a54fe2-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 1351, 'output_tokens': 3, 'total_tokens': 1354}}]})\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={} response_metadata={} id='89bc7111-09d7-4f79-81d0-f94887d6f8a0'\n",
      "=========================\n",
      "content='' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 1276, 'output_tokens': 85, 'total_tokens': 1361}, 'tool_calls': [{'id': '9f6j3bxes', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 85, 'prompt_tokens': 1276, 'total_tokens': 1361, 'completion_time': 0.154545455, 'prompt_time': 0.024289597, 'queue_time': 0.252771272, 'total_time': 0.178835052}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--10b5b2a5-8c9f-4067-9b69-7c5a4ccba275-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': '9f6j3bxes', 'type': 'tool_call'}]\n",
      "=========================\n",
      "content='6' name='multiply' id='4b4d8b72-8bfc-415d-9898-87e31500ea9a' tool_call_id='9f6j3bxes'\n",
      "=========================\n",
      "content='6' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 1353, 'output_tokens': 3, 'total_tokens': 1356}} response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 1353, 'total_tokens': 1356, 'completion_time': 0.005454545, 'prompt_time': 0.025661447, 'queue_time': 0.258576192, 'total_time': 0.031115992}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--cafa2e87-6503-4a1c-bdcb-222276a00c22-0'\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {},
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {},
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 0199a6e6-d833-7135-9f98-44ddb4c3d92a\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: hfd99w80z, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: hfd99w80z, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "AI: 6\n",
      "--------------------------------------------------\n",
      "AI: 6\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
