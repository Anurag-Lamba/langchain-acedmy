{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147e576c",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/edit-state-human-feedback.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239520-lesson-3-editing-state-and-human-feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f2448-21c3-4196-9e61-0b47e7d0048b",
   "metadata": {},
   "source": [
    "# Editing graph state\n",
    "\n",
    "## Review\n",
    "\n",
    "We discussed motivations for human-in-the-loop:\n",
    "\n",
    "(1) `Approval` - We can interrupt our agent, surface state to a user, and allow the user to accept an action\n",
    "\n",
    "(2) `Debugging` - We can rewind the graph to reproduce or avoid issues\n",
    "\n",
    "(3) `Editing` - You can modify the state \n",
    "\n",
    "We showed how breakpoints support user approval, but don't yet know how to modify our graph state once our graph is interrupted!\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's show how to directly edit the graph state and insert human feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d26b8c-d958-4d21-9ca4-4636d3dfe45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk langgraph-prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5948594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, getpass\n",
    "\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50faae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8df1f-a76a-4803-a532-ea9802106ac8",
   "metadata": {},
   "source": [
    "## Editing state \n",
    "\n",
    "Previously, we introduced breakpoints.\n",
    "\n",
    "We used them to interrupt the graph and await user approval before executing the next node.\n",
    "\n",
    "But breakpoints are also [opportunities to modify the graph state](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/).\n",
    "\n",
    "Let's set up our agent with a breakpoint before the `assistant` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf24f05-ac2b-455e-846c-0c50ac86e1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\langchain-acedmy\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a by b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(groq_api_key=GROQ_API_KEY,model='gemma2-9b-it')\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dfe84af-5c62-4c3f-8ed7-96b5261f0b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine the control flow\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"assistant\"], checkpointer=memory)\n",
    "\n",
    "# Show\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a47fd5-1f60-41dc-9206-698ed8ece530",
   "metadata": {},
   "source": [
    "Let's run!\n",
    "\n",
    "We can see the graph is interrupted before the chat model responds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ce488d-00e4-492e-a62c-dd98702c313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": \"Multiply 2 and 3\"}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4be478ef-bd60-4d32-8a05-5f56c93a8396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='9311c428-c5c8-45ae-9788-30702bfe7773')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a0369-b670-6f5f-8000-a4f2fa2517d7'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-10-03T08:54:44.438614+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0a0369-b66c-60ec-bfff-0bf1bf98d4f7'}}, tasks=(PregelTask(id='89a86d8e-a469-1151-ced4-3aa8e74cef26', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = graph.get_state(thread)\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef63a1-2ab8-416d-babf-d35054e294f0",
   "metadata": {},
   "source": [
    "Now, we can directly apply a state update.\n",
    "\n",
    "Remember, updates to the `messages` key will use the `add_messages` reducer:\n",
    " \n",
    "* If we want to over-write the existing message, we can supply the message `id`.\n",
    "* If we simply want to append to our list of messages, then we can pass a message without an `id` specified, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9179cff1-e529-473a-9ce2-e23b932c2063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0a0369-b6b5-6a4f-8001-c9d7e5193131'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(\n",
    "    thread,\n",
    "    {\"messages\": [HumanMessage(content=\"No, actually multiply 3 and 3!\")]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b8d6a-8c7b-4f7a-b723-121af25ac829",
   "metadata": {},
   "source": [
    "Let's have a look.\n",
    "\n",
    "We called `update_state` with a new message. \n",
    "\n",
    "The `add_messages` reducer appends it to our state key, `messages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "141b6aab-ec6d-44f3-beb1-6c22ac5f2158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "No, actually multiply 3 and 3!\n"
     ]
    }
   ],
   "source": [
    "new_state = graph.get_state(thread).values\n",
    "for m in new_state['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4041959-cc3a-4168-8cf7-06d1711921d8",
   "metadata": {},
   "source": [
    "Now, let's proceed with our agent, simply by passing `None` and allowing it proceed from the current state.\n",
    "\n",
    "We emit the current and then proceed to execute the remaining nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f166bed2-87c9-41ec-b235-0305721c2d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "No, actually multiply 3 and 3!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (yws79gjqz)\n",
      " Call ID: yws79gjqz\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18dc1ca",
   "metadata": {},
   "source": [
    "Now, we're back at the `assistant`, which has our `breakpoint`.\n",
    "\n",
    "We can again pass `None` to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5952731-0170-4589-a399-ee787df35400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc22c3e9-b00c-4ead-b752-a682b45b3718",
   "metadata": {},
   "source": [
    "### Editing graph state in Studio\n",
    "\n",
    "**⚠️ DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- 🚀 API: http://127.0.0.1:2024\n",
    "- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- 📚 API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "020efeba-fa80-4839-81f9-9ce228f9844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'google.colab' in str(get_ipython()):\n",
    "#     raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "642aabab-f822-4917-9d66-3314ac5008fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the URL of the local development server\n",
    "from langgraph_sdk import get_client\n",
    "client = get_client(url=\"http://127.0.0.1:2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be74cb09",
   "metadata": {},
   "source": [
    "Our agent is defined in `studio/agent.py`. \n",
    "\n",
    "If you look at the code, you'll see that it *does not* have a breakpoint! \n",
    " \n",
    "Of course, we can add it to `agent.py`, but one very nice feature of the API is that we can pass in a breakpoint!\n",
    "\n",
    "Here, we pass a `interrupt_before=[\"assistant\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c352f9e-6a0f-4a94-a083-b85b0233efa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '3d83b76a-034f-4ea4-8590-b8a8869f69a0', 'example': False}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\"messages\": \"Multiply 2 and 3\"}\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    \"agent\",\n",
    "    input=initial_input,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"assistant\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13065dd9-5f43-47d6-ac2a-9dc15c0c54e6",
   "metadata": {},
   "source": [
    "We can get the current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4da2c464-3e71-496a-badc-671aeee168b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': {'messages': [{'content': 'Multiply 2 and 3',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': '3d83b76a-034f-4ea4-8590-b8a8869f69a0',\n",
       "    'example': False}]},\n",
       " 'next': ['assistant'],\n",
       " 'tasks': [{'id': '90d7b251-388f-40dc-8aa5-d1147558b952',\n",
       "   'name': 'assistant',\n",
       "   'path': ['__pregel_pull', 'assistant'],\n",
       "   'error': None,\n",
       "   'interrupts': [],\n",
       "   'checkpoint': None,\n",
       "   'state': None,\n",
       "   'result': None}],\n",
       " 'metadata': {'langgraph_auth_user': None,\n",
       "  'langgraph_auth_user_id': '',\n",
       "  'langgraph_auth_permissions': [],\n",
       "  'langgraph_request_id': 'a604edf1-69f2-47b2-93fe-4eb64c8a056c',\n",
       "  'graph_id': 'agent',\n",
       "  'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       "  'user_id': '',\n",
       "  'created_by': 'system',\n",
       "  'run_attempt': 1,\n",
       "  'langgraph_version': '0.6.8',\n",
       "  'langgraph_api_version': '0.4.35',\n",
       "  'langgraph_plan': 'developer',\n",
       "  'langgraph_host': 'self-hosted',\n",
       "  'langgraph_api_url': 'http://127.0.0.1:2024',\n",
       "  'run_id': '0199a937-3358-7022-9403-4bf25628396a',\n",
       "  'thread_id': 'a208b4bb-027d-461f-8faf-fb37fa45fd1a',\n",
       "  'source': 'loop',\n",
       "  'step': 0,\n",
       "  'parents': {}},\n",
       " 'created_at': '2025-10-03T08:36:32.193486+00:00',\n",
       " 'checkpoint': {'checkpoint_id': '1f0a0341-05fa-6e0f-8000-2e7cae8aaafe',\n",
       "  'thread_id': 'a208b4bb-027d-461f-8faf-fb37fa45fd1a',\n",
       "  'checkpoint_ns': ''},\n",
       " 'parent_checkpoint': {'checkpoint_id': '1f0a0341-05fa-6e0e-bfff-7c6b36cb61b6',\n",
       "  'thread_id': 'a208b4bb-027d-461f-8faf-fb37fa45fd1a',\n",
       "  'checkpoint_ns': ''},\n",
       " 'interrupts': [],\n",
       " 'checkpoint_id': '1f0a0341-05fa-6e0f-8000-2e7cae8aaafe',\n",
       " 'parent_checkpoint_id': '1f0a0341-05fa-6e0e-bfff-7c6b36cb61b6'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_state = await client.threads.get_state(thread['thread_id'])\n",
    "current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4527bbf1-0927-41a6-aeef-d15e32bbbdc3",
   "metadata": {},
   "source": [
    "We can look at the last message in state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "801ae2d9-0551-46b8-aee2-82293cee4011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Multiply 2 and 3',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {},\n",
       " 'type': 'human',\n",
       " 'name': None,\n",
       " 'id': '3d83b76a-034f-4ea4-8590-b8a8869f69a0',\n",
       " 'example': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_message = current_state['values']['messages'][-1]\n",
    "last_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0581ba8-db3d-474d-9042-b1c7f3461caf",
   "metadata": {},
   "source": [
    "We can edit it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86b12be7-7e4a-40d0-8521-dced7c393c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'No, actually multiply 3 and 3!',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {},\n",
       " 'type': 'human',\n",
       " 'name': None,\n",
       " 'id': '3d83b76a-034f-4ea4-8590-b8a8869f69a0',\n",
       " 'example': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_message['content'] = \"No, actually multiply 3 and 3!\"\n",
    "last_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f84f2c24-f281-4591-90e5-de3a5547c9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'No, actually multiply 3 and 3!',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {},\n",
       " 'type': 'human',\n",
       " 'name': None,\n",
       " 'id': '3d83b76a-034f-4ea4-8590-b8a8869f69a0',\n",
       " 'example': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b4280-6ae7-4246-9c87-44e0daa6c654",
   "metadata": {},
   "source": [
    "Remember, as we said before, updates to the `messages` key will use the same `add_messages` reducer. \n",
    "\n",
    "If we want to over-write the existing message, then we can supply the message `id`.\n",
    "\n",
    "Here, we did that. We only modified the message `content`, as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84d33b6e-32ff-4eca-8114-345e508f3481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'checkpoint': {'thread_id': 'a208b4bb-027d-461f-8faf-fb37fa45fd1a',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0a0345-2a37-67ab-8001-59f02a60702d'},\n",
       " 'configurable': {'thread_id': 'a208b4bb-027d-461f-8faf-fb37fa45fd1a',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0a0345-2a37-67ab-8001-59f02a60702d'},\n",
       " 'checkpoint_id': '1f0a0345-2a37-67ab-8001-59f02a60702d'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.threads.update_state(thread['thread_id'], {\"messages\": last_message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2e195cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': {'messages': [{'content': 'No, actually multiply 3 and 3!',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': '3d83b76a-034f-4ea4-8590-b8a8869f69a0',\n",
       "    'example': False}]},\n",
       " 'next': ['assistant'],\n",
       " 'tasks': [{'id': '24e456ba-771e-4638-4242-2de05dd45e16',\n",
       "   'name': 'assistant',\n",
       "   'path': ['__pregel_pull', 'assistant'],\n",
       "   'error': None,\n",
       "   'interrupts': [],\n",
       "   'checkpoint': None,\n",
       "   'state': None,\n",
       "   'result': None}],\n",
       " 'metadata': {'graph_id': 'agent',\n",
       "  'thread_id': 'a208b4bb-027d-461f-8faf-fb37fa45fd1a',\n",
       "  'source': 'update',\n",
       "  'step': 1,\n",
       "  'parents': {}},\n",
       " 'created_at': '2025-10-03T08:38:23.367364+00:00',\n",
       " 'checkpoint': {'checkpoint_id': '1f0a0345-2a37-67ab-8001-59f02a60702d',\n",
       "  'thread_id': 'a208b4bb-027d-461f-8faf-fb37fa45fd1a',\n",
       "  'checkpoint_ns': ''},\n",
       " 'parent_checkpoint': {'checkpoint_id': '1f0a0341-05fa-6e0f-8000-2e7cae8aaafe',\n",
       "  'thread_id': 'a208b4bb-027d-461f-8faf-fb37fa45fd1a',\n",
       "  'checkpoint_ns': ''},\n",
       " 'interrupts': [],\n",
       " 'checkpoint_id': '1f0a0345-2a37-67ab-8001-59f02a60702d',\n",
       " 'parent_checkpoint_id': '1f0a0341-05fa-6e0f-8000-2e7cae8aaafe'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_state1 = await client.threads.get_state(thread['thread_id'])\n",
    "current_state1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f07f0d1-7083-4827-babd-d3702eb59a37",
   "metadata": {},
   "source": [
    "Now, we resume by passing `None`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef18d12d-e0a6-487a-9f32-ad30e2634a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': 'No, actually multiply 3 and 3!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '3d83b76a-034f-4ea4-8590-b8a8869f69a0', 'example': False}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'yeh6x2h1n', 'function': {'arguments': '{\"a\":3,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'token_usage': {'completion_tokens': 85, 'prompt_tokens': 1280, 'total_tokens': 1365, 'completion_time': 0.154545455, 'prompt_time': 0.024443014, 'queue_time': 0.258063146, 'total_time': 0.178988469}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--9d78d3e6-835c-40e7-929b-af524ae4cd76-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 3, 'b': 3}, 'id': 'yeh6x2h1n', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 1280, 'output_tokens': 85, 'total_tokens': 1365}}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '9', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '413ca6a9-9253-4665-8eee-13fb74e96daa', 'tool_call_id': 'yeh6x2h1n', 'artifact': None, 'status': 'success'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=None,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"assistant\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a82dd35-cbc8-486d-8e20-10d0c4d138d6",
   "metadata": {},
   "source": [
    "We get the result of the tool call as `9`, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d1bb3c7-dc26-4c32-b3df-865f41ef3c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '9', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '413ca6a9-9253-4665-8eee-13fb74e96daa', 'tool_call_id': 'yeh6x2h1n', 'artifact': None, 'status': 'success'}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '9', 'additional_kwargs': {}, 'response_metadata': {'token_usage': {'completion_tokens': 3, 'prompt_tokens': 1357, 'total_tokens': 1360, 'completion_time': 0.005454545, 'prompt_time': 0.025735604, 'queue_time': 0.256976965, 'total_time': 0.031190149}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--81b76148-71ca-42a2-8fb8-003cfc16cf31-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 1357, 'output_tokens': 3, 'total_tokens': 1360}}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=None,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"assistant\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914c5ca-27e4-421c-835a-9e4327dac12f",
   "metadata": {},
   "source": [
    "## Awaiting user input\n",
    "\n",
    "So, it's clear that we can edit our agent state after a breakpoint.\n",
    "\n",
    "Now, what if we want to allow for human feedback to perform this state update?\n",
    "\n",
    "We'll add a node that [serves as a placeholder for human feedback](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/wait-user-input/#setup) within our agent.\n",
    "\n",
    "This `human_feedback` node allow the user to add feedback directly to state.\n",
    " \n",
    "We specify the breakpoint using `interrupt_before` our `human_feedback` node.\n",
    "\n",
    "We set up a checkpointer to save the state of the graph up until this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6af5d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "# Replace with the correct path on your system\n",
    "os.environ[\"PYPPETEER_CHROMIUM_EXECUTABLE\"] = r\"C:\\Program Files\\Microsoft\\Edge\\Application\\msedge.exe\"\n",
    "\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4b475ff-681f-4660-80dd-d6ade7bd48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# no-op node that should be interrupted on\n",
    "def human_feedback(state: MessagesState):\n",
    "    pass\n",
    "\n",
    "# Assistant node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "\n",
    "# Define edges: these determine the control flow\n",
    "builder.add_edge(START, \"human_feedback\")\n",
    "builder.add_edge(\"human_feedback\", \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"human_feedback\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"human_feedback\"], checkpointer=memory)\n",
    "\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png(max_retries=5, retry_delay=2.0,draw_method=MermaidDrawMethod.PYPPETEER)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d4ceb6-a224-4307-8196-3f53d367df5c",
   "metadata": {},
   "source": [
    "We will get feedback from the user.\n",
    "\n",
    "We use `.update_state` to update the state of the graph with the human response we get, as before.\n",
    "\n",
    "We use the `as_node=\"human_feedback\"` parameter to apply this state update as the specified node, `human_feedback`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fc7bcd6-660c-4a8a-ad8d-e6698dcf6201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "no, multiply 3 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (34snwkv5p)\n",
      " Call ID: 34snwkv5p\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": \"Multiply 2 and 3\"}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    \n",
    "# Get user input\n",
    "user_input = input(\"Tell me how you want to update the state: \")\n",
    "\n",
    "# We now update the state as if we are the human_feedback node\n",
    "graph.update_state(thread, {\"messages\": user_input}, as_node=\"human_feedback\")\n",
    "\n",
    "# Continue the graph execution\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abf4cf5f-c0cb-4fdb-be6b-271ae4e967e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Continue the graph execution\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e96ccc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
