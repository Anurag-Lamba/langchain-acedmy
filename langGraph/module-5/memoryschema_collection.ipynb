{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with Collection Schema \n",
    "\n",
    "## Review\n",
    "\n",
    "We extended our chatbot to save semantic memories to a single [user profile](https://langchain-ai.github.io/langgraph/concepts/memory/#profile). \n",
    "\n",
    "We also introduced a library, [Trustcall](https://github.com/hinthornw/trustcall), to update this schema with new information. \n",
    "\n",
    "## Goals\n",
    "\n",
    "Sometimes we want to save memories to a [collection](https://docs.google.com/presentation/d/181mvjlgsnxudQI6S3ritg9sooNyu4AcLLFH1UK0kIuk/edit#slide=id.g30eb3c8cf10_0_200) rather than single profile. \n",
    "\n",
    "Here we'll update our chatbot to [save memories to a collection](https://langchain-ai.github.io/langgraph/concepts/memory/#collection).\n",
    "\n",
    "We'll also show how to use [Trustcall](https://github.com/hinthornw/trustcall) to update this collection. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain_openai langgraph trustcall langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, getpass\n",
    "\n",
    "# def _set_env(var: str):\n",
    "#     # Check if the variable is set in the OS environment\n",
    "#     env_value = os.environ.get(var)\n",
    "#     if not env_value:\n",
    "#         # If not set, prompt the user for input\n",
    "#         env_value = getpass.getpass(f\"{var}: \")\n",
    "    \n",
    "#     # Set the environment variable for the current process\n",
    "#     os.environ[var] = env_value\n",
    "\n",
    "# _set_env(\"LANGSMITH_API_KEY\")\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "# os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a collection schema\n",
    "\n",
    "Instead of storing user information in a fixed profile structure, we'll create a flexible collection schema to store memories about user interactions.\n",
    "\n",
    "Each memory will be stored as a separate entry with a single `content` field for the main information we want to remember\n",
    "\n",
    "This approach allows us to build an open-ended collection of memories that can grow and change as we learn more about the user.\n",
    "\n",
    "We can define a collection schema as a [Pydantic](https://docs.pydantic.dev/latest/) object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    \"\"\"Extract a memory from the user's conversation.\"\"\"\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    \"\"\"A collection of extracted user memories.\"\"\"\n",
    "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can used LangChain's chat model [chat model](https://python.langchain.com/docs/concepts/chat_models/) interface's [`with_structured_output`](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) method to enforce structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\langchain-acedmy\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Memory(content=\"User's name is Lance.\"),\n",
       " Memory(content='User likes to bike.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the model\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(groq_api_key=GROQ_API_KEY,model='openai/gpt-oss-120b')\n",
    "\n",
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(MemoryCollection)\n",
    "\n",
    "# Invoke the model to produce structured output that matches the schema\n",
    "memory_collection = model_with_structure.invoke([HumanMessage(\"My name is Lance. I like to bike.\")])\n",
    "memory_collection.memories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `model_dump()` to serialize a Pydantic model instance into a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"User's name is Lance.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_collection.memories[0].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dictionary representation of each memory to the store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Initialize the in-memory store\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memories\")\n",
    "\n",
    "# Save a memory to namespace as key and value\n",
    "key = str(uuid.uuid4())\n",
    "value = memory_collection.memories[0].model_dump()\n",
    "in_memory_store.put(namespace_for_memory, key, value)\n",
    "\n",
    "key = str(uuid.uuid4())\n",
    "value = memory_collection.memories[1].model_dump()\n",
    "in_memory_store.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for memories in the store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['1', 'memories'], 'key': '2b611e19-80d3-4e53-87e1-10a41684899e', 'value': {'content': \"User's name is Lance.\"}, 'created_at': '2025-10-03T17:01:47.089373+00:00', 'updated_at': '2025-10-03T17:01:47.089373+00:00', 'score': None}\n",
      "{'namespace': ['1', 'memories'], 'key': 'a5dbabc5-2484-49e2-b1f4-cac4f001ac43', 'value': {'content': 'User likes to bike.'}, 'created_at': '2025-10-03T17:01:47.089373+00:00', 'updated_at': '2025-10-03T17:01:47.089373+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Search \n",
    "for m in in_memory_store.search(namespace_for_memory):\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating collection schema\n",
    "\n",
    "We discussed the challenges with updating a profile schema in the last lesson. \n",
    "\n",
    "The same applies for collections! \n",
    "\n",
    "We want the ability to update the collection with new memories as well as update existing memories in the collection. \n",
    "\n",
    "Now we'll show that [Trustcall](https://github.com/hinthornw/trustcall) can be also used to update a collection. \n",
    "\n",
    "This enables both addition of new memories as well as [updating existing memories in the collection](https://github.com/hinthornw/trustcall?tab=readme-ov-file#simultanous-updates--insertions\n",
    ").\n",
    "\n",
    "Let's define a new extractor with Trustcall. \n",
    "\n",
    "As before, we provide the schema for each memory, `Memory`.  \n",
    "\n",
    "But, we can supply `enable_inserts=True` to allow the extractor to insert new memories to the collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instruction\n",
    "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
    "\n",
    "# Conversation\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Lance.\"), \n",
    "                AIMessage(content=\"Nice to meet you, Lance.\"), \n",
    "                HumanMessage(content=\"This morning I had a nice bike ride in San Francisco.\")]\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (fc_6f920b22-a8b4-4f14-a8d9-f95e9a291621)\n",
      " Call ID: fc_6f920b22-a8b4-4f14-a8d9-f95e9a291621\n",
      "  Args:\n",
      "    content: User had a nice bike ride this morning in San Francisco.\n"
     ]
    }
   ],
   "source": [
    "# Messages contain the tool calls\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='User had a nice bike ride this morning in San Francisco.'\n"
     ]
    }
   ],
   "source": [
    "# Responses contain the memories that adhere to the schema\n",
    "for m in result[\"responses\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'fc_6f920b22-a8b4-4f14-a8d9-f95e9a291621'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',\n",
       "  'Memory',\n",
       "  {'content': 'User had a nice bike ride this morning in San Francisco.'})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [AIMessage(content=\"That's great, did you do after?\"), \n",
    "                        HumanMessage(content=\"I went to Tartine and ate a croissant.\"),                        \n",
    "                        AIMessage(content=\"What else is on your mind?\"),\n",
    "                        HumanMessage(content=\"I was thinking about my Japan, and going back this winter!\"),]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = \"\"\"Update existing memories and create new ones based on the following conversation:\"\"\"\n",
    "\n",
    "# We'll save existing memories, giving them an ID, key (tool name), and value\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the extractor with our updated conversation and existing memories\n",
    "result = trustcall_extractor.invoke({\"messages\": updated_conversation, \n",
    "                                     \"existing\": existing_memories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (fc_4e68076b-f0f4-4042-9bc3-57d60209f323)\n",
      " Call ID: fc_4e68076b-f0f4-4042-9bc3-57d60209f323\n",
      "  Args:\n",
      "    content: User went to Tartine and ate a croissant.\n"
     ]
    }
   ],
   "source": [
    "# Messages from the model indicate two tool calls were made\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='User went to Tartine and ate a croissant.'\n"
     ]
    }
   ],
   "source": [
    "# Responses contain the memories that adhere to the schema\n",
    "for m in result[\"responses\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that we updated the first memory in the collection by specifying the `json_doc_id`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'fc_4e68076b-f0f4-4042-9bc3-57d60209f323'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 'Memory', {'content': 'User went to Tartine and ate a croissant.'})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_memories1 = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith trace: \n",
    "\n",
    "https://smith.langchain.com/public/ebc1cb01-f021-4794-80c0-c75d6ea90446/r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot with collection schema updating\n",
    "\n",
    "Now, let's bring Trustcall into our chatbot to create and update a memory collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "import uuid\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langchain_core.messages import merge_message_runs\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.base import BaseStore\n",
    "from trustcall import create_extractor\n",
    "\n",
    "# Initialize the model\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Memory schema\n",
    "class Memory(BaseModel):\n",
    "    \"\"\"Extract a memory from the user's conversation.\"\"\"\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "# Create the Trustcall extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    # This allows the extractor to insert new memories\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful chatbot. You are designed to be a companion to a user. \n",
    "\n",
    "You have a long term memory which keeps track of information you learn about the user over time.\n",
    "\n",
    "Current Memory (may include updated memories from this conversation): \n",
    "\n",
    "{memory}\"\"\"\n",
    "\n",
    "# Trustcall instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Reflect on following interaction. \n",
    "\n",
    "Use the provided tools to retain any necessary memories about the user. \n",
    "\n",
    "Use parallel tool calling to handle updates and insertions simultaneously:\"\"\"\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memories from the store and use them to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memories\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    info = \"\\n\".join(f\"- {mem.value['content']}\" for mem in memories)\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=info)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"memories\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"Memory\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items\n",
    "                          else None\n",
    "                        )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION)] + state[\"messages\"]))\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = trustcall_extractor.invoke({\"messages\": updated_messages, \n",
    "                                        \"existing\": existing_memories})\n",
    "\n",
    "    # Save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Lance! I’ve made a note of your name so I can address you properly in future conversations. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Lance\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike around San Francisco\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it—bike enthusiast in San Francisco! 🚲  \n",
      "\n",
      "Do you have any favorite routes or neighborhoods you like to ride through?  \n",
      "Maybe the Golden Gate Park loop, the Embarcadero waterfront, or the hills around Twin Peaks? I’d love to hear about your go‑to spots (or any bike‑related plans you’ve got coming up).\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I like to bike around San Francisco\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['memories', '1'], 'key': 'c5876799-5f25-4878-aa4f-fb48046eb4fb', 'value': {'content': \"User's name is Lance\"}, 'created_at': '2025-10-03T17:04:33.094652+00:00', 'updated_at': '2025-10-03T17:04:33.094652+00:00', 'score': None}\n",
      "{'namespace': ['memories', '1'], 'key': '1231e560-7ce9-401c-a568-22c8b5525fda', 'value': {'content': 'User likes to bike around San Francisco'}, 'created_at': '2025-10-03T17:04:41.208936+00:00', 'updated_at': '2025-10-03T17:04:41.208936+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memories\", user_id)\n",
    "memories = across_thread_memory.search(namespace)\n",
    "for m in memories:\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I also enjoy going to bakeries\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great, a bike‑and‑bakery fan! I’ve added that to my notes.  \n",
      "\n",
      "Here are a few ideas that combine both of your interests around San Francisco:\n",
      "\n",
      "| Neighborhood / Route | Bakery Stop (or nearby) | Why it’s a good combo |\n",
      "|----------------------|--------------------------|-----------------------|\n",
      "| **Golden Gate Park → Inner Sunset** | **Tartine Manufactory** (325 Divisadero St) | After a loop around the park, ride down Fulton St to the famous Tartine for fresh pastries and a coffee. |\n",
      "| **The Embarcadero → Financial District** | **Boudin Bakery Café** (160 Jefferson St) | Cruise the waterfront, then pop into the historic sour‑dough bakery for a quick snack before heading back. |\n",
      "| **Twin Peaks → Noe Valley** | **Noe Valley Bakery** (4422 24th St) | Conquer the hills, then treat yourself to a croissant or a slice of cake in a cozy neighborhood spot. |\n",
      "| **Mission District Loop** | **Flour Bakery** (2401 Market St) | Ride along the Mission’s vibrant streets and stop for a buttery almond croissant or a seasonal tart. |\n",
      "| **Presidio → Marina District** | **The Mill** (736 Divisadero St) | After a scenic ride through the Presidio, swing by The Mill for its famous toast with house‑made jam and a strong espresso. |\n",
      "\n",
      "If any of those sound good, I can give you more details (hours, best‑time‑to‑go, bike‑friendly parking, etc.) or suggest other hidden‑gem bakeries you might not have tried yet.  \n",
      "\n",
      "Anything in particular you’re craving right now—croissants, sour‑dough, something sweet or savory? Or do you have a favorite route you’d like to pair with a bakery stop?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I also enjoy going to bakeries\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue the conversation in a new thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What bakeries do you recommend for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hey Lance! 🚴‍♂️🍞 Since you love biking around San Francisco and have a soft spot for bakeries, I’ve put together a little “bike‑and‑bake” tour for you. All of these spots are either right on bike lanes or just a short walk from a safe bike path, so you can roll in, grab a treat, and keep cruising.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. **Tartine Bakery – Mission District**\n",
      "- **Why it’s great for bikers:** Right off 24th St. and Mission, there’s a protected bike lane and a bike‑rack right in front.\n",
      "- **Must‑try:** Morning bun, Country loaf, and the famous **Meyer Lemon Tart**.\n",
      "- **Tip:** Go early (around 7 am) to beat the line and enjoy the fresh morning air.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. **Arsicault Bakery – SoMa**\n",
      "- **Why it’s great for bikers:** Located on 2nd St., near the Embarcadero Bike Path and a dedicated bike rack.\n",
      "- **Must‑try:** Their buttery **croissants** (especially the almond and chocolate‑hazelnut) and the **pain au chocolat**.\n",
      "- **Tip:** Pair it with a quick stroll along the waterfront—great for a post‑bike coffee break.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. **B. Patisserie – Pacific Heights**\n",
      "- **Why it’s great for bikers:** A short ride up on Fell St. (bike‑friendly) and there’s a bike‑rack on the corner.\n",
      "- **Must‑try:** The **kouign‑amann** (a caramelized, buttery pastry) and the **matcha‑green tea cake**.\n",
      "- **Tip:** After your treat, ride up to Lafayette Park for a quick scenic view of the city.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. **Miette Patisserie – Ferry Building / Hayes Valley**\n",
      "- **Why it’s great for bikers:** The Ferry Building has plenty of bike racks and the nearby Market St. bike lane is smooth. The Hayes Valley location is also bike‑friendly.\n",
      "- **Must‑try:** Their **lemon‑poppy seed cake** and the **rose‑petal macarons**.\n",
      "- **Tip:** Grab a pastry, hop on the Embarcadero path, and enjoy the bay breeze on your way back.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. **Jane on Fillmore – Pacific Heights**\n",
      "- **Why it’s great for bikers:** Nestled on Fillmore St., just off the 19th St. bike lane, with a bike rack on the sidewalk.\n",
      "- **Must‑try:** The **cinnamon roll** and the **chocolate hazelnut scone**.\n",
      "- **Tip:** Pair it with a quick ride down to the Presidio’s Crissy Field for a waterfront snack stop.\n",
      "\n",
      "---\n",
      "\n",
      "## 6. **Baker & Mill – SoMa (inside the Ferry Building)**\n",
      "- **Why it’s great for bikers:** Directly inside the Ferry Building—plenty of bike racks and easy access from the Embarcadero path.\n",
      "- **Must‑try:** Their **sourdough bagel** (try it with smoked salmon) and the **seasonal fruit tarts**.\n",
      "- **Tip:** This is a perfect “break‑and‑refuel” spot if you’re doing a longer ride along the waterfront.\n",
      "\n",
      "---\n",
      "\n",
      "## 7. **La Boulangerie – Noe Valley**\n",
      "- **Why it’s great for bikers:** Located on 24th St., with a protected bike lane and a small bike rack out front.\n",
      "- **Must‑try:** The **pain aux raisins** and the **almond croissant**.\n",
      "- **Tip:** After a bite, ride the 24th‑St. bike lane all the way up to the Twin Peaks viewpoint for a rewarding view.\n",
      "\n",
      "---\n",
      "\n",
      "### Quick “Bike‑and‑Bakery” Route Idea\n",
      "If you want a half‑day adventure, try this loop:\n",
      "\n",
      "1. **Start** at **Tartine** (Mission) – grab a morning bun.\n",
      "2. **Bike** up Valencia St. to **Arsicault** (SoMa) – enjoy a croissant.\n",
      "3. **Head** north on the Embarcadero to **Miette** (Ferry Building) – treat yourself to a macaron.\n",
      "4. **Take** the hill‑climbing route on 19th St. to **Jane on Fillmore** – indulge in a cinnamon roll.\n",
      "5. **Descend** via Fulton St. back to the Mission, finishing where you started.\n",
      "\n",
      "Total distance: ~6 miles, mostly on bike‑friendly streets, and you’ll have sampled a wide range of San Fran’s best pastries.\n",
      "\n",
      "---\n",
      "\n",
      "### A Few Bike‑Friendly Tips\n",
      "- **Lock it up:** Most bakeries have a bike rack or a sturdy post. Bring a U‑lock for extra security.\n",
      "- **Carry a small tote or backpack:** It’s easier to stash a pastry (or two) than to juggle a bag while riding.\n",
      "- **Hydrate:** Some spots (like the Ferry Building) have water fountains—great for a quick sip after a ride.\n",
      "- **Timing:** Weekday mornings (7–9 am) are usually less crowded, both on the road and inside the bakery.\n",
      "\n",
      "---\n",
      "\n",
      "Hope this gives you a tasty (and pedal‑powered) itinerary! Let me know which one you try first, or if you have a favorite type of pastry you’d like me to hunt down. Happy riding and happy munching! 🌉🥐🚲\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"What bakeries do you recommend for me?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith \n",
    "\n",
    "https://smith.langchain.com/public/c87543ec-b426-4a82-a3ab-94d01c01d9f4/r\n",
    "\n",
    "## Studio\n",
    "\n",
    "![Screenshot 2024-10-30 at 11.29.25 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6732d0876d3daa19fef993ba_Screenshot%202024-11-11%20at%207.50.21%E2%80%AFPM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
